
https://drive.google.com/drive/u/0/folders/15MjGztgW3_xLT0ap0v8xfrckf0JGXhMF

Aim:
To implement NLP programs using python.
Algorithm:
Text Preprocessing
Since, text is the most unstructured form of all the available data, various types of noise are present
in it and the data is not readily analyzable without any pre-processing. The entire process of cleaning
and standardization of text, making it noise-free and ready for analysis is known as text
preprocessing.
It is predominantly comprised of three steps:
1. Noise Removal
2.Lexicon Normalization
3.Object Standardization
Noise Removal
Any piece of text which is not relevant to the context of the data and the end-output can be
specified as the noise.
For example – language stopwords (commonly used words of a language – is, am, the, of, in etc),
URLs or links, social media entities (mentions, hashtags), punctuations and industry specific words.
This step deals with removal of all types of noisy entities present in the text.
A general approach for noise removal is to prepare a dictionary of noisy entities, and iterate the text
object by tokens (or by words), eliminating those tokens which are present in the noise dictionary.
PROGRAM:
import pandas as pd
import nltk
from nltk.sentiment.vader import
SentimentIntensityAnalyzer nltk.download('all')
# reading and wragling data
df_avatar = pd.read_csv('avatar.csv', encoding = 'unicode_escape',
engi ne='python')
df_avatar_lines = df_avatar.groupby('character').count()
df_avatar_lines = df_avatar_lines.sort_values(by=['character_words'],
a scending=False)[:10]
top_character_names = df_avatar_lines.index.values
# filtering out non-top characters
df_character_sentiment =
df_avatar[df_avatar['character'].isin(top_char acter_names)]
df_character_sentiment = df_character_sentiment[['character',

'characte r_words']]
# calculating sentiment score
sid = SentimentIntensityAnalyzer()
df_character_sentiment.reset_index(inplace=True, drop=True)
df_character_sentiment[['neg', 'neu', 'pos', 'compound']] =
df_characte
r_sentiment['character_words'].apply(sid.polarity_scores).apply(pd.Ser
i es)
df_character_sentiment

import matplotlib.pyplot as plt
import numpy as np
# preparing data
X = np.arange(len(df_character_sentiment['pos']))
#bar plot
fig = plt.figure(figsize = (17, 12))
plt.barh(X, df_character_sentiment['pos'], facecolor='#9999ff', edgecol
or='white')
plt.barh(X, -
df_character_sentiment['neg'], facecolor='#ff9999',
edgecolor='white') # plt.rcParams.update({'font.size':13})
plt.xlim([-.16,.22])
plt.yticks(ticks=X, labels=df_character_sentiment['character'], rotatio
n='0')
plt.show()

import spacy
nlp = spacy.load("en_core_web_sm")
doc = nlp("Biden invites Ukrainian president to White House this
summer ")
print([(X.text, X.label_) for X in doc.ents])
from nltk.stem import PorterStemmer
from nltk.stem import LancasterStemmer
# PorterStemmer
porter = PorterStemmer()
# LancasterStemmer
lancaster = LancasterStemmer()
print(porter.stem("friendship"))
print(lancaster.stem("friendship"))
from nltk import WordNetLemmatizer
lemmatizer = WordNetLemmatizer()
words = ['be', 'is', 'are', 'were', 'was']
for word in words:
print(lemmatizer.lemmatize(word, pos='v'))

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer text

= ["I love writing code in Python. I love Python code", "I hate
writing code in Java. I hate Java code"] df =
pd.DataFrame({'review': ['review1', 'review2'], 'text':text}) cv =
CountVectorizer(stop_words='english')
cv_matrix = cv.fit_transform(df['text'])
df_dtm = pd.DataFrame(cv_matrix.toarray(),
index=df['review'].values,
columns=cv.get_feature_names()) df_dtm

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer text
= ["I love writing code in Python. I love Python code", "I hate
writing code in Java. I hate Java code"] df =
pd.DataFrame({'review': ['review1', 'review2'], 'text':text})
tfidf = TfidfVectorizer(stop_words='english', norm=None)
tfidf_matrix = tfidf.fit_transform(df['text'])
df_dtm = pd.DataFrame(tfidf_matrix.toarray(),
index=df['review'].values,
columns=tfidf.get_feature_names()) df_dtm
OUTPUT:

RESULT:
Implementation of NLP using Python is carried out successfully.
